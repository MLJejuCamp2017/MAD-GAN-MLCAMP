{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-41389fad42b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import pprint\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "from six.moves import xrange\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_integer(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 128, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", , \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", None, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"celebA\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Directory name to save the checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Directory name to save the image samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def main(_):\n",
    "  pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "  if FLAGS.input_width is None:\n",
    "    FLAGS.input_width = FLAGS.input_height\n",
    "  if FLAGS.output_width is None:\n",
    "    FLAGS.output_width = FLAGS.output_height\n",
    "\n",
    "  if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "    os.makedirs(FLAGS.checkpoint_dir)\n",
    "  if not os.path.exists(FLAGS.sample_dir):\n",
    "    os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "  #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "  run_config = tf.ConfigProto()\n",
    "  run_config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c1dc5ef5c66a>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-c1dc5ef5c66a>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    flags.DEFINE_integer(\"input_width\", , \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "  with tf.Session(config=run_config) as sess:\n",
    "        \n",
    "#     if FLAGS.dataset == 'mnist':\n",
    "#       dcgan = DCGAN(\n",
    "#           sess,\n",
    "#           input_width=FLAGS.input_width,\n",
    "#           input_height=FLAGS.input_height,\n",
    "#           output_width=FLAGS.output_width,\n",
    "#           output_height=FLAGS.output_height,\n",
    "#           batch_size=FLAGS.batch_size,\n",
    "#           sample_num=FLAGS.batch_size,\n",
    "#           y_dim=10,\n",
    "#           dataset_name=FLAGS.dataset,\n",
    "#           input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "#           crop=FLAGS.crop,\n",
    "#           checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "#           sample_dir=FLAGS.sample_dir)\n",
    "#     else:\n",
    "#       dcgan = DCGAN(\n",
    "#           sess,\n",
    "#           input_width=FLAGS.input_width,\n",
    "#           input_height=FLAGS.input_height,\n",
    "#           output_width=FLAGS.output_width,\n",
    "#           output_height=FLAGS.output_height,\n",
    "    #           batch_size=FLAGS.batch_size,\n",
    "#           sample_num=FLAGS.batch_size,\n",
    "#           dataset_name=FLAGS.dataset,\n",
    "#           input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "#           crop=FLAGS.crop,\n",
    "#           checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "#           sample_dir=FLAGS.sample_dir)\n",
    "\n",
    "#     show_all_variables()\n",
    "\n",
    "#     if FLAGS.train:\n",
    "#       dcgan.train(FLAGS)\n",
    "#     else:\n",
    "#       if not dcgan.load(FLAGS.checkpoint_dir)[0]:\n",
    "#         raise Exception(\"[!] Train a model first, then run test mode\")\n",
    "      \n",
    "\n",
    "#     OPTION = 1\n",
    "#     visualize(sess, dcgan, FLAGS, OPTION)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow_environment]",
   "language": "python",
   "name": "Python [tensorflow_environment]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
